{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "corpus3_sentences = []\n",
    "f = open('corpus3.txt','r')\n",
    "corpus3_sentences=f.readlines()\n",
    "f.close()\n",
    "\n",
    "corpus4_sentences = []\n",
    "f = open('corpus4.txt','r',encoding='utf-8')\n",
    "corpus4_sentences=f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenizer(sentence):\n",
    "    scanner = re.Scanner([\n",
    "        (b\"[\\x80-\\xff]+\", lambda scanner,token: (\"EMOJI\",token)),\n",
    "        (r\"[a-zA-Z0-9]+@([a-zA-Z0-9]+\\.*){2,3}\",lambda scanner,token: (\"EMAIL\",token)),\n",
    "        (r\"http[s]*://[A-Z0-9a-z./]*\",lambda scanner,token: (\"LINK\",token)),\n",
    "        (r\"#\\S+\",lambda scanner,token: (\"HASHTAG\",token)),\n",
    "        (r\"@\\S+\",lambda scanner,token: (\"MENTION\",token)),\n",
    "        (r'[A-Z][a-z]*\\.', lambda scanner, token: (\"NNP\",token)),\n",
    "        (r\"[0-9]+% | [0-9]+\\ %\", lambda scanner,token: (\"PERCENT\",token)),\n",
    "        (r\"[0-9.]+\", lambda scanner,token: (\"DECIMAL\",token)),\n",
    "        (r\"\\w+\", lambda scanner,token: (\"WORD\",token)),\n",
    "        (r\"$[0-9]+(.[0-9]+)*\",lambda scanner,token: (\"CURRENCY\",token)),\n",
    "        (r\"\\s+\",lambda scanner,token: None),\n",
    "        (r\"\\n\",lambda scanner,token: None),\n",
    "        (r\"\\\\n\",lambda scanner,token: None),\n",
    "        (r\"[0-9]+\", lambda scanner,token: (\"NUMBERS\",token)),\n",
    "        (r\"[\\\",.?!`'â€™\\-@&;\\(\\):\\/#$\\*\\|=]+\", lambda scanner,token: (\"PUNC\",token)),\n",
    "    ])\n",
    "    results,remainder = scanner.scan(sentence)\n",
    "\n",
    "    if(len(remainder)>0):\n",
    "        print(sentence)\n",
    "        print(results)\n",
    "        print(remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for line in corpus3_sentences:\n",
    "        # print(line)\n",
    "        word_tokenizer(line.encode('utf-8'))\n",
    "    \n",
    "    # for line in corpus4_sentences:\n",
    "    #     word_tokenizer(line.encode('utf-8'))\n",
    "    # word_tokenizer(b'Rev. St. Francis of Assisi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
