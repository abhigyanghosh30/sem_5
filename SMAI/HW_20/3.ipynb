{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init as weight_init\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "#parameters\n",
    "batch_size = 128\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])\n",
    "\n",
    "#Loading the train set file\n",
    "dataset = datasets.MNIST(root='./data',\n",
    "                            transform=preprocess,  \n",
    "                            download=True)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,20),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(20, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 28*28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h = self.encoder(x)\n",
    "        xr = self.decoder(h)\n",
    "        return xr,h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1e-2\n",
    "weight_decay = 1e-5\n",
    "net = AE()\n",
    "net = net.to(device)\n",
    "optimizer = torch.optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "def train(num_epochs = 50):\n",
    "    epochLoss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, cntr = 0, 0\n",
    "\n",
    "        for i,(images,_) in enumerate(loader):\n",
    "\n",
    "            images = images.view(-1, 28*28)\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Initialize gradients to 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass (this calls the \"forward\" function within Net)\n",
    "            outputs, _ = net(images)\n",
    "\n",
    "            # Find the loss\n",
    "            loss = criterion(outputs, images)\n",
    "\n",
    "            # Find the gradients of all weights using the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights using the optimizer and scheduler\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            cntr += 1\n",
    "\n",
    "    #     scheduler.step(total_loss/cntr)\n",
    "        print ('Epoch [%d/%d], Loss: %.4f' \n",
    "                       %(epoch+1, num_epochs, total_loss/cntr))\n",
    "        epochLoss.append(total_loss/cntr)\n",
    "    return epochLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.4745\n",
      "Epoch [2/50], Loss: 1.3888\n",
      "Epoch [3/50], Loss: 1.5239\n",
      "Epoch [4/50], Loss: 1.3672\n",
      "Epoch [5/50], Loss: 1.3687\n",
      "Epoch [6/50], Loss: 1.6003\n",
      "Epoch [7/50], Loss: 1.4203\n",
      "Epoch [8/50], Loss: 1.4933\n",
      "Epoch [9/50], Loss: 1.5200\n",
      "Epoch [10/50], Loss: 1.4593\n",
      "Epoch [11/50], Loss: 1.2394\n",
      "Epoch [12/50], Loss: 0.8446\n",
      "Epoch [13/50], Loss: 1.0230\n",
      "Epoch [14/50], Loss: 1.4936\n",
      "Epoch [15/50], Loss: 1.3484\n",
      "Epoch [16/50], Loss: 1.3810\n",
      "Epoch [17/50], Loss: 1.4634\n",
      "Epoch [18/50], Loss: 1.4559\n",
      "Epoch [19/50], Loss: 1.4815\n",
      "Epoch [20/50], Loss: 1.4375\n",
      "Epoch [21/50], Loss: 1.2742\n",
      "Epoch [22/50], Loss: 1.1295\n",
      "Epoch [23/50], Loss: 0.7118\n",
      "Epoch [24/50], Loss: 0.7170\n",
      "Epoch [25/50], Loss: 0.7114\n",
      "Epoch [26/50], Loss: 0.8895\n",
      "Epoch [27/50], Loss: 0.7115\n",
      "Epoch [28/50], Loss: 0.7917\n",
      "Epoch [29/50], Loss: 0.7112\n",
      "Epoch [30/50], Loss: 0.7295\n",
      "Epoch [31/50], Loss: 0.7112\n",
      "Epoch [32/50], Loss: 0.7123\n",
      "Epoch [33/50], Loss: 0.7197\n",
      "Epoch [34/50], Loss: 0.7112\n",
      "Epoch [35/50], Loss: 0.7113\n",
      "Epoch [36/50], Loss: 0.7323\n",
      "Epoch [37/50], Loss: 0.7113\n",
      "Epoch [38/50], Loss: 0.7113\n",
      "Epoch [39/50], Loss: 1.1503\n",
      "Epoch [40/50], Loss: 0.7753\n",
      "Epoch [41/50], Loss: 0.5530\n",
      "Epoch [42/50], Loss: 0.5255\n",
      "Epoch [43/50], Loss: 0.5059\n",
      "Epoch [44/50], Loss: 0.4970\n",
      "Epoch [45/50], Loss: 0.4917\n",
      "Epoch [46/50], Loss: 0.4885\n",
      "Epoch [47/50], Loss: 0.4854\n",
      "Epoch [48/50], Loss: 0.4844\n",
      "Epoch [49/50], Loss: 0.4827\n",
      "Epoch [50/50], Loss: 0.4804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4745078707046346,\n",
       " 1.3887574123675381,\n",
       " 1.5239177581343823,\n",
       " 1.3671875106754587,\n",
       " 1.368736672757277,\n",
       " 1.6003218147037888,\n",
       " 1.42033065204173,\n",
       " 1.493271048389264,\n",
       " 1.5199946632771604,\n",
       " 1.4592721210613941,\n",
       " 1.2394373127138183,\n",
       " 0.8445918735410614,\n",
       " 1.0229771491815287,\n",
       " 1.4936184916160762,\n",
       " 1.3484401438536167,\n",
       " 1.3809959954544426,\n",
       " 1.4633906899230567,\n",
       " 1.4559181420279463,\n",
       " 1.4815368332079988,\n",
       " 1.437520218937636,\n",
       " 1.2742042259366781,\n",
       " 1.1295095768564545,\n",
       " 0.7117902983480425,\n",
       " 0.7170050585193675,\n",
       " 0.7113781751854333,\n",
       " 0.8894749297770356,\n",
       " 0.7115073354005306,\n",
       " 0.7916703736349973,\n",
       " 0.7111923535749602,\n",
       " 0.7294961988036313,\n",
       " 0.7111657167802742,\n",
       " 0.7123258491314804,\n",
       " 0.7197357710998958,\n",
       " 0.7111622841119258,\n",
       " 0.7112965727411608,\n",
       " 0.7322640399943029,\n",
       " 0.7112574574789767,\n",
       " 0.711305244009632,\n",
       " 1.1502524912992775,\n",
       " 0.7753150047523889,\n",
       " 0.5529984953179796,\n",
       " 0.5254777169812208,\n",
       " 0.5059298743952566,\n",
       " 0.49704156863664006,\n",
       " 0.4916747366187415,\n",
       " 0.4884732321762581,\n",
       " 0.48537342571246345,\n",
       " 0.4844444676248758,\n",
       " 0.4827269506988241,\n",
       " 0.4803928262008024]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 320)\n",
    "        self.fc2 = nn.Linear(320, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x,dim=1)\n",
    "\n",
    "class RedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RedNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 15)\n",
    "        self.fc2 = nn.Linear(15, 12)\n",
    "        self.fc3 = nn.Linear(12, 10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnet = FullNet()\n",
    "fnet.to(device)\n",
    "rnet = RedNet()\n",
    "rnet.to(device)\n",
    "\n",
    "optimizer_fnet = torch.optim.SGD(fnet.parameters(), lr=learning_rate)\n",
    "optimizer_rnet = torch.optim.SGD(rnet.parameters(), lr=learning_rate)\n",
    "criterion_fnet = nn.CrossEntropyLoss()\n",
    "criterion_rnet = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_full(num_epochs = 50):\n",
    "    epochLoss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, cntr = 0, 0\n",
    "\n",
    "        for i,(images,labels) in enumerate(loader):\n",
    "\n",
    "            images = images.view(-1, 28*28)\n",
    "            images,labels = images.to(device),labels.to(device)\n",
    "\n",
    "            # Initialize gradients to 0\n",
    "            optimizer_fnet.zero_grad()\n",
    "\n",
    "            # Forward pass (this calls the \"forward\" function within Net)\n",
    "            full, red = net(images)\n",
    "            out_fnet = fnet(full)\n",
    "            \n",
    "            # Find the loss\n",
    "            loss_full = criterion_fnet(out_fnet,labels)\n",
    "            \n",
    "            # Find the gradients of all weights using the loss\n",
    "            loss_full.backward()\n",
    "            \n",
    "            # Update the weights using the optimizer and scheduler\n",
    "            optimizer_fnet.step()\n",
    "            \n",
    "            total_loss += loss_full.item()\n",
    "            cntr += 1\n",
    "\n",
    "    #     scheduler.step(total_loss/cntr)\n",
    "        print ('Epoch [%d/%d], Loss: %.4f' \n",
    "                       %(epoch+1, num_epochs, total_loss/cntr))\n",
    "        epochLoss.append(total_loss/cntr)\n",
    "    return epochLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 2.2808\n",
      "Epoch [2/50], Loss: 2.2158\n",
      "Epoch [3/50], Loss: 2.0771\n",
      "Epoch [4/50], Loss: 1.9404\n",
      "Epoch [5/50], Loss: 1.8302\n",
      "Epoch [6/50], Loss: 1.7381\n",
      "Epoch [7/50], Loss: 1.6914\n",
      "Epoch [8/50], Loss: 1.6686\n",
      "Epoch [9/50], Loss: 1.6548\n",
      "Epoch [10/50], Loss: 1.6452\n",
      "Epoch [11/50], Loss: 1.6379\n",
      "Epoch [12/50], Loss: 1.6322\n",
      "Epoch [13/50], Loss: 1.6275\n",
      "Epoch [14/50], Loss: 1.6237\n",
      "Epoch [15/50], Loss: 1.6204\n",
      "Epoch [16/50], Loss: 1.6177\n",
      "Epoch [17/50], Loss: 1.6153\n",
      "Epoch [18/50], Loss: 1.6130\n",
      "Epoch [19/50], Loss: 1.6111\n",
      "Epoch [20/50], Loss: 1.6094\n",
      "Epoch [21/50], Loss: 1.6078\n",
      "Epoch [22/50], Loss: 1.6063\n",
      "Epoch [23/50], Loss: 1.6049\n",
      "Epoch [24/50], Loss: 1.6037\n",
      "Epoch [25/50], Loss: 1.6024\n",
      "Epoch [26/50], Loss: 1.6014\n",
      "Epoch [27/50], Loss: 1.6004\n",
      "Epoch [28/50], Loss: 1.5995\n",
      "Epoch [29/50], Loss: 1.5985\n",
      "Epoch [30/50], Loss: 1.5976\n",
      "Epoch [31/50], Loss: 1.5969\n",
      "Epoch [32/50], Loss: 1.5960\n",
      "Epoch [33/50], Loss: 1.5953\n",
      "Epoch [34/50], Loss: 1.5946\n",
      "Epoch [35/50], Loss: 1.5940\n",
      "Epoch [36/50], Loss: 1.5934\n",
      "Epoch [37/50], Loss: 1.5928\n",
      "Epoch [38/50], Loss: 1.5922\n",
      "Epoch [39/50], Loss: 1.5916\n",
      "Epoch [40/50], Loss: 1.5911\n",
      "Epoch [41/50], Loss: 1.5905\n",
      "Epoch [42/50], Loss: 1.5900\n",
      "Epoch [43/50], Loss: 1.5895\n",
      "Epoch [44/50], Loss: 1.5890\n",
      "Epoch [45/50], Loss: 1.5886\n",
      "Epoch [46/50], Loss: 1.5881\n",
      "Epoch [47/50], Loss: 1.5876\n",
      "Epoch [48/50], Loss: 1.5873\n",
      "Epoch [49/50], Loss: 1.5868\n",
      "Epoch [50/50], Loss: 1.5864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2808221931904873,\n",
       " 2.215758320110947,\n",
       " 2.0771129243155277,\n",
       " 1.9404132132337037,\n",
       " 1.8302344304920515,\n",
       " 1.7381436903593637,\n",
       " 1.6914477020438545,\n",
       " 1.6685973433797547,\n",
       " 1.6548013003396074,\n",
       " 1.6451801178551941,\n",
       " 1.6379338421547083,\n",
       " 1.6322340004479707,\n",
       " 1.6275464250588976,\n",
       " 1.6236702658728497,\n",
       " 1.6204166676698208,\n",
       " 1.6176703583711245,\n",
       " 1.6152534988134908,\n",
       " 1.613047860832865,\n",
       " 1.6110934224972593,\n",
       " 1.609395239398932,\n",
       " 1.6077661178767808,\n",
       " 1.606256331716265,\n",
       " 1.6049362278696317,\n",
       " 1.6036807565546747,\n",
       " 1.6024412613179384,\n",
       " 1.601430276563681,\n",
       " 1.600378854442507,\n",
       " 1.5994562884129442,\n",
       " 1.5985317591156787,\n",
       " 1.5976496934890747,\n",
       " 1.596874540548589,\n",
       " 1.5960401759218814,\n",
       " 1.5952564798184294,\n",
       " 1.5945969606513408,\n",
       " 1.5940281124765685,\n",
       " 1.5933633519134034,\n",
       " 1.5928026394549208,\n",
       " 1.5921963468543503,\n",
       " 1.5916354897688192,\n",
       " 1.591051027464714,\n",
       " 1.590519185259398,\n",
       " 1.5900276993383478,\n",
       " 1.5895246585040712,\n",
       " 1.5890038610775588,\n",
       " 1.5885506827694011,\n",
       " 1.5881324993776107,\n",
       " 1.5876412925435537,\n",
       " 1.5872652421373803,\n",
       " 1.5867975886696692,\n",
       " 1.5864220084920366]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_red(num_epochs = 50):\n",
    "    epochLoss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, cntr = 0, 0\n",
    "\n",
    "        for i,(images,labels) in enumerate(loader):\n",
    "\n",
    "            images = images.view(-1, 28*28)\n",
    "            images,labels = images.to(device),labels.to(device)\n",
    "\n",
    "            # Initialize gradients to 0\n",
    "            optimizer_rnet.zero_grad()\n",
    "\n",
    "            # Forward pass (this calls the \"forward\" function within Net)\n",
    "            full, red = net(images)\n",
    "            out_rnet = rnet(red)\n",
    "            \n",
    "            # Find the loss\n",
    "            loss_red = criterion_rnet(out_rnet,labels)\n",
    "            \n",
    "            # Find the gradients of all weights using the loss\n",
    "            loss_red.backward()\n",
    "            \n",
    "            # Update the weights using the optimizer and scheduler\n",
    "            optimizer_rnet.step()\n",
    "            \n",
    "            total_loss += loss_red.item()\n",
    "            cntr += 1\n",
    "\n",
    "    #     scheduler.step(total_loss/cntr)\n",
    "        print ('Epoch [%d/%d], Loss: %.4f' \n",
    "                       %(epoch+1, num_epochs, total_loss/cntr))\n",
    "        epochLoss.append(total_loss/cntr)\n",
    "    return epochLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 2.2855\n",
      "Epoch [2/50], Loss: 2.1918\n",
      "Epoch [3/50], Loss: 2.1208\n",
      "Epoch [4/50], Loss: 2.0744\n",
      "Epoch [5/50], Loss: 2.0460\n",
      "Epoch [6/50], Loss: 1.9941\n",
      "Epoch [7/50], Loss: 1.9579\n",
      "Epoch [8/50], Loss: 1.9338\n"
     ]
    }
   ],
   "source": [
    "train_red()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
